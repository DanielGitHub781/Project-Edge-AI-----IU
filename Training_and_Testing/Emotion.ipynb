{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Emotion Prediction</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T08:23:50.838054Z",
     "iopub.status.busy": "2025-09-18T08:23:50.837666Z",
     "iopub.status.idle": "2025-09-18T08:23:57.815636Z",
     "shell.execute_reply": "2025-09-18T08:23:57.814814Z",
     "shell.execute_reply.started": "2025-09-18T08:23:50.837954Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = \"emotion_dataset/labels\"\n",
    "\n",
    "label_counts = Counter()\n",
    "\n",
    "for label_file in os.listdir(labels_path):\n",
    "    if label_file.endswith(\".txt\"):\n",
    "        with open(os.path.join(labels_path, label_file), \"r\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if parts:  \n",
    "                    label = int(parts[0])   \n",
    "                    label_counts[label] += 1\n",
    "\n",
    "labels = sorted(label_counts.keys())\n",
    "counts = [label_counts[l] for l in labels]\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=labels, y=counts, palette=\"pastel\")\n",
    "plt.title(\"Number of Pictures per Label Category\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve accuracy we will remove all off the labes except 4,5 and 6. Which equal to Happy, Neutral and Sad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_images = \"emotion_dataset/images\"\n",
    "path_labels = \"emotion_dataset/labels\"\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for img_file in os.listdir(path_images):\n",
    "    img_id, _ = os.path.splitext(img_file)\n",
    "    label_file = os.path.join(path_labels, img_id + \".txt\")\n",
    "    \n",
    "    if not os.path.exists(label_file):\n",
    "        continue\n",
    "    \n",
    "    with open(label_file, \"r\") as f:\n",
    "        parts = f.readline().strip().split()\n",
    "        if not parts:\n",
    "            continue\n",
    "        label = int(parts[0])\n",
    "    \n",
    "    if label not in [4, 5, 6]:\n",
    "        continue\n",
    "    \n",
    "    with Image.open(os.path.join(path_images, img_file)) as img:\n",
    "        images.append(img.copy())\n",
    "        labels.append(label)\n",
    "\n",
    "df = pd.DataFrame({\"Images\": images, \"Labels\": labels})\n",
    "\n",
    "print(\"Loaded:\", len(df), \"images from categories 4, 5, 6\")\n",
    "\n",
    "counts = df[\"Labels\"].value_counts().sort_index()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=counts.index, y=counts.values, palette=\"pastel\")\n",
    "plt.title(\"Number of Pictures per Label Category\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "print(df[\"Labels\"].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T08:25:19.020927Z",
     "iopub.status.busy": "2025-09-18T08:25:19.020577Z",
     "iopub.status.idle": "2025-09-18T08:25:19.057915Z",
     "shell.execute_reply": "2025-09-18T08:25:19.057172Z",
     "shell.execute_reply.started": "2025-09-18T08:25:19.020890Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "display(df[\"Images\"][3])\n",
    "print(df[\"Labels\"][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T08:25:21.691305Z",
     "iopub.status.busy": "2025-09-18T08:25:21.690930Z",
     "iopub.status.idle": "2025-09-18T08:25:21.724601Z",
     "shell.execute_reply": "2025-09-18T08:25:21.723602Z",
     "shell.execute_reply.started": "2025-09-18T08:25:21.691267Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "display(df[\"Images\"][4])\n",
    "print(df[\"Labels\"][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df[\"Images\"][5000])\n",
    "print(df[\"Labels\"][5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T08:26:17.122628Z",
     "iopub.status.busy": "2025-09-18T08:26:17.122273Z",
     "iopub.status.idle": "2025-09-18T08:26:33.206176Z",
     "shell.execute_reply": "2025-09-18T08:26:33.205260Z",
     "shell.execute_reply.started": "2025-09-18T08:26:17.122594Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "for i in range(len(df)):\n",
    "    img_resized = df[\"Images\"].iloc[i].resize((96, 96), Image.Resampling.LANCZOS)\n",
    "    df.at[i, \"Images\"] = img_resized\n",
    "    x.append(np.asarray(img_resized))\n",
    "\n",
    "x = np.array(x) / 255.0 \n",
    "y = np.array(df[\"Labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T08:26:33.208542Z",
     "iopub.status.busy": "2025-09-18T08:26:33.208279Z",
     "iopub.status.idle": "2025-09-18T08:26:33.836320Z",
     "shell.execute_reply": "2025-09-18T08:26:33.835473Z",
     "shell.execute_reply.started": "2025-09-18T08:26:33.208515Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_mapped = y - 4 \n",
    "num_classes = 3\n",
    "y_onehot = to_categorical(y_mapped, num_classes=num_classes)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y_onehot, test_size=0.2, stratify=y_mapped, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./1.,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./1.)\n",
    "\n",
    "train_generator = train_datagen.flow(x_train, y_train, batch_size=32)\n",
    "test_generator = test_datagen.flow(x_test, y_test, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "emotion_model = Sequential()\n",
    "emotion_model.add(Conv2D(32, (3,3), activation=\"relu\", input_shape=(96, 96, 3)))\n",
    "emotion_model.add(MaxPooling2D((2,2)))\n",
    "emotion_model.add(Conv2D(64, (3,3), activation=\"relu\"))\n",
    "emotion_model.add(MaxPooling2D((2,2)))\n",
    "emotion_model.add(Conv2D(128, (3,3), activation=\"relu\"))\n",
    "emotion_model.add(MaxPooling2D((2,2)))\n",
    "emotion_model.add(Flatten())\n",
    "emotion_model.add(Dense(64, activation=\"relu\"))\n",
    "emotion_model.add(Dropout(0.5))\n",
    "emotion_model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "emotion_model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=optimizers.Adam(learning_rate=0.0001),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_labels = y_mapped\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_labels),\n",
    "    y=y_labels\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "print(\"Class weights:\", class_weights_dict)\n",
    "\n",
    "history = emotion_model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=test_generator,\n",
    "    shuffle=True,\n",
    "    class_weight=class_weights_dict\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = emotion_model.evaluate(test_generator, verbose=1)\n",
    "print(\"Final Test Loss (Emotion):\", test_loss)\n",
    "print(\"Final Test Accuracy (Emotion):\", test_accuracy)\n",
    "\n",
    "emotion_model.save(\"emotion_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_and_predict_emotion(file):\n",
    "    \n",
    "    im = Image.open(file)\n",
    "    width, height = im.size\n",
    "\n",
    "  \n",
    "    if width != height:\n",
    "        if width > height:\n",
    "            left = width / 2 - height / 2\n",
    "            right = width / 2 + height / 2\n",
    "            top = 0\n",
    "            bottom = height\n",
    "        else:\n",
    "            left = 0\n",
    "            right = width\n",
    "            top = 0\n",
    "            bottom = width\n",
    "        im = im.crop((left, top, right, bottom))\n",
    "\n",
    "    im = im.resize((96, 96), Image.Resampling.LANCZOS)\n",
    "\n",
    "    ar = np.asarray(im).astype(\"float32\") / 255.0\n",
    "    ar = ar.reshape(-1, 96, 96, 3) \n",
    "\n",
    "    pred_probs = emotion_model.predict(ar)[0]          \n",
    "    pred_class = np.argmax(pred_probs)                 \n",
    "    emotion_label = pred_class + 4                     \n",
    "\n",
    "    prediction = {\"emotion\": emotion_label}\n",
    "    print(f\"{file} -> Predicted Emotion: {emotion_label}\")\n",
    "\n",
    "    return im, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_folder = \"test\"\n",
    "results = {}\n",
    "\n",
    "for filename in os.listdir(test_folder):\n",
    "    if not (filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\")):\n",
    "        continue  \n",
    "    \n",
    "    img_path = os.path.join(test_folder, filename)\n",
    "    im_resized, prediction = process_and_predict_emotion(img_path)\n",
    "    \n",
    "    \n",
    "    results[filename] = prediction\n",
    "    \n",
    "    \n",
    "    plt.imshow(im_resized)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"{filename} → Emotion: {prediction['emotion']}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"emotion_model.h5\")\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"emotion_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"emotion_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_predict_emotion_tflite(file):\n",
    "\n",
    "    im = Image.open(file).convert(\"RGB\")\n",
    "    \n",
    "    im_resized = im.resize((96, 96), Image.Resampling.LANCZOS)\n",
    "\n",
    "    ar = np.asarray(im_resized).astype('float32') / 255.0\n",
    "    ar = np.expand_dims(ar, axis=0)  \n",
    "\n",
    "    interpreter.set_tensor(input_details[0]['index'], ar)\n",
    "\n",
    "    interpreter.invoke()\n",
    "\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "\n",
    "    emotion_classes = [\"Happy\", \"Neutral\", \"Sad\"]\n",
    "    predicted_idx = np.argmax(output_data)\n",
    "    predicted_emotion = emotion_classes[predicted_idx]\n",
    "\n",
    "    return im_resized, {\"emotion\": predicted_emotion, \"raw_output\": output_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = \"test\"\n",
    "results = {}\n",
    "\n",
    "for filename in os.listdir(test_folder):\n",
    "    if not (filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\")):\n",
    "        continue \n",
    "    \n",
    "    img_path = os.path.join(test_folder, filename)\n",
    "    im_resized, prediction = process_and_predict_emotion_tflite(img_path)\n",
    "    \n",
    "    results[filename] = prediction\n",
    "    \n",
    "    plt.imshow(im_resized)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"{filename} → Emotion: {prediction[\"emotion\"]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tflite(model_path, x_data, task=\"binary\"):\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    preds = []\n",
    "\n",
    "    for i in range(len(x_data)):\n",
    "        input_data = x_data[i].reshape(1, 96, 96, 3).astype(input_details[0][\"dtype\"])\n",
    "        interpreter.set_tensor(input_details[0][\"index\"], input_data)\n",
    "        interpreter.invoke()\n",
    "        output_data = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "        preds.append(output_data[0])\n",
    "\n",
    "    preds = np.array(preds)\n",
    "\n",
    "    if task == \"multi_class\":\n",
    "        preds = np.argmax(preds, axis=1) \n",
    "    elif task == \"binary\":\n",
    "        preds = np.round(preds).astype(int).reshape(-1)\n",
    "    else:\n",
    "        raise ValueError(\"task must be 'binary' or 'multi_class'\")\n",
    "\n",
    "    return preds\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model_path, x_test, y_test, model_name=\"\", task=\"binary\"):\n",
    "    preds = predict_tflite(model_path, x_test, task=task)\n",
    "\n",
    "    if len(y_test.shape) > 1 and y_test.shape[1] > 1:\n",
    "        y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "    precision = precision_score(y_test, preds, average=\"weighted\", zero_division=0)\n",
    "    recall = recall_score(y_test, preds, average=\"weighted\", zero_division=0)\n",
    "    f1 = f1_score(y_test, preds, average=\"weighted\", zero_division=0)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "    print(f\" Results for {model_name} ({model_path}):\")\n",
    "    print(f\"  Accuracy : {accuracy:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall   : {recall:.4f}\")\n",
    "    print(f\"  F1-Score : {f1:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "\n",
    "evaluate_model(\"emotion_model.tflite\", x_test, y_test, model_name=\"Emotion Model\", task=\"multi_class\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 44109,
     "sourceId": 78156,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1209087,
     "sourceId": 2020033,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1209242,
     "sourceId": 2020285,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1209296,
     "sourceId": 2020375,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1209298,
     "sourceId": 2020377,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1209385,
     "sourceId": 2020508,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1209456,
     "sourceId": 2020684,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1230160,
     "sourceId": 2053178,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30066,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
